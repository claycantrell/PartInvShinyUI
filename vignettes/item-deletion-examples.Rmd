---
title: "Applied examples"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Applied examples}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}`
  
---

```{r, include = FALSE, warning=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, warning=FALSE, message=FALSE}
library(PartInvShinyUI)
library(lavaan)
```
\newcommand{\SR}{\text{SR}}
\newcommand{\SE}{\text{SE}}
\newcommand{\SP}{\text{SP}}
\newcommand{\PS}{\text{PS}}
\newcommand{\str}{\text{str}}
\newcommand{\par}{\text{par}}
\newcommand{\td}{\tilde}

### Proposed Notation

Let $I$ denote the set of items in a k-element scale, $I = \{i_1, i_2,\ldots,i_k\}$.
We will denote the set of items excluding a specific item $i_k$ as 
$(-k)$, e.g., if the third item $i_3$ is excluded, the remaining set of items 
will be denoted by $(-3)$. If referring to the $h$ or $\Delta h$ associated with
the removal of an item $i_k$, the operation $h(I,I-i_k)$ can be referred to as 
$h^{(-k)}$ and $\Delta h(I,I-i_k))$ as $\Delta h^{(-k)}$. Accuracy indices will be
referred to by the two letter acronym e.g., $\SE$, and 'overall' accuracy indices 
will be denoted with a tilde over the two letter acronym, e.g., $\td{\SE}$, 
$\td{\SR}$ etc. We can reserve the superscript for non-comparison attributes, 
e.g., SE under partial invariance: $\SE^{\par}$, SE for item set $I-i_k$ for the 
reference group: $\SE^{(-k);r}$, and reserve the subscript of the acronym to 
indicate that the current operation (e.g., $\Delta h$) is being performed on h 
values. For instance, on Cohen's h values associated with the comparison between
SAI under strict vs. partial invariance, for the reference group: 
$\SE_{\str,\par}^{r}$. We can use commas in subscripts of acronyms to indicate 
the pair of groups/conditions compared, and semicolons
in superscripts to conditions constant across the group/conditions being compared.
The superscript of h or $\Delta h$ on the other hand refers to the current comparison.

- `h_overall_sai.par`: Cohen's h effect size for the improvement/drop in overall
SAI when item $i_k$ is removed (under partial invariance): e.g.,
$h^{(-k)}(\td{\SE}^{\par})$ for performing the operation on SE under partial 
invariance. The resulting h values: $h^{(-k)}_{\td{\SE}^{\par}}$.

- `delta_h$h_R_vs_Ef.par`: Effect size of the change in `h$R_vs_Ef.par` when item
`i_k` is dropped. `h$R_vs_Ef.par` is the Cohen's effect size for the comparison 
in selection accuracy indices for the reference group vs. the focal group if it
followed the same distribution as the reference group, for a given set of items 
under partial invariance. We can denote this as, for SE, $\Delta h^{(-k)}(h_{\SE^{\par}_{r,Ef}})$.

- `delta_h$h_str_vs_par.ref`: Effect size of the change in `h$str_vs_par$ref` 
when item `i_k` is dropped. `h$str_vs_par$ref` refers to the Cohen's effect size
for the comparison in selection accuracy indices under strict invariance vs. 
partial invariance, for a given set of items for the reference group. We can 
denote this as: $\Delta h^{(-k)}(h_{\SE^{r}_{\str,\par}})$.


## Example from Lai, Kwok, Yoon and Hsiao (2017) 
Center for Epidemiological Studies Depression  (CES-D) Scale 
Positive Affect Factor

Items: good (biased), hopeful, happy, enjoyed

```{r}
ex1 <- item_deletion_h(weights_item = c(1, 1, 1,  1), 
                              propsel =.14, n_dim = 1,  
                              alpha_r = 0,
                              alpha_f =-0.125,
                              psi_r = 0.354^2,
                              psi_f = 0.329^2,
                              lambda_r_p = c(1.00, 1.66, 2.30, 2.29),
                              lambda_f_p = c(1.00, 1.66, 2.30, 2.29),
                              nu_r_p = c(1.54, 1.36, 1.16, 1.08),
                              nu_f_p = c(0.68, 1.36, 1.16, 1.08),
                              theta_r_p = diag(c(1.20, 0.81, 0.32, 0.32)), 
                              theta_f_p = diag(c(0.72, 0.81, 0.32, 0.32)),
                              weights_latent = 1,
                              plot_contour = FALSE,
                              return_detailed = FALSE,
                              also_return_PartInvMulti_outputs = FALSE,
                              pmix_ref = 5/7)
```

The first element of the results, `h_overall_sai.par`, is a list containing effect sizes showing the change in
a selection accuracy index (SAI) under for the full item set vs. when one 
item is deleted, using parameter estimates from the partial invariance model. 
'Overall' refers to the weighting of accuracy indices for the focal and reference 
groups by the group proportions to arrive at a weighted average for each index.

[HL]: # (For the last sentence above, could you define the overall index in formula? Are they the weighted averages of true positive/false positive?)

[HL]: # (Also note: I would use 'PI' or 'PFI' as an abbreviation for partial (factorial) invariance)


\[
\begin{align*}
h^{(-k)}(\td{\SR}^{\par}) &= 2\arcsin(\sqrt{\td{\SR}^{\par}})-2\arcsin(\sqrt{\td{\SR}^{(-k);\par}})\\
&=h^{(-k)}_{\td{\SR}^{\par}}
\end{align*}
\]
```{r}
# HL: Maybe show all four as all of them are discussed below?
knitr::kable(ex1$h_overall_sai.par)
```
For the 4-item CES-D scale, the negative $h^{(-i)}_{\td{\SR}^{\par}}$,
$h^{(-1)}_{\td{\SE}^{\par}}$, and $h^{(-1)}_{\td{\SP}^{\par}}$ values 
indicate that removing the first item would lead to an improvement in success ratio, 
sensitivity, and specificity as the reduced set of items led to a larger
SR, SE, SP. Removing any of the other items would harm SR, SE, SP (indicated by the
positive h values). For instance, SR when item 2 is removed must be lower than
SR for the full item set for a positive $h^{(-2)}_{\td{\SR}^{\par}}$ to be 
computed. Then, a negative `h_overall_sai_par` indicates an improvement 
in performance whereas a positive `h_overall_sai_par` indicates a deterioration
in performance.

[HL]: # (We can call the following 'bias'. It'd be helpful to discuss the 'full' column first.)

`h$R_vs_Ef.par` is the effect size of the comparison between accuracy indices 
for the reference group vs. the expected indices for the focal group if it 
followed the same distribution as the reference group under partial invariance. When strict invariance holds, the $h_{R - EF}(\PS)$ values are zero.

[HL]: # (Maybe we just call it $h_{\Delta\PS, F}$)

\[
\begin{align*}
h^{r,Ef}(\PS^{\par}) &= 2\text{arcsin}(\sqrt{\PS^{\par}_r})-2\text{arcsin}(\sqrt{\PS^{\par}_{Ef}})\\
&=h_{\PS^{\par}_{r,Ef}}
\end{align*}
\]
\[
\begin{align*}
h^{r,Ef}(\PS^{(-k);\par}) &= 2\text{arcsin}(\sqrt{\PS^{(-k);\par}_r})-2\text{arcsin}(\sqrt{\PS^{(-k);\par}_{Ef}})\\
&=h_{\PS^{(-k);\par}_{r,Ef}}
\end{align*}
\]
```{r }
knitr::kable(ex1$h$R_vs_Ef.par)
```

The 0 values for $h_{\PS^{(-1);\par}_{r,Ef}}$,$h_{\SR^{(-1);\par}_{r,Ef}}$,
$h_{\SE^{(-1);\par}_{r,Ef}}$, $h_{\SP^{(-1);\par}_{r,Ef}}$ indicate that 
if we delete the first item, the accuracy indices for the Efocal group under
partial invariance will be equal to that of the reference group under partial 
invariance, *thus removing bias*. 

For the full set of items, we see that $h_{\PS^{\par}_{r,Ef}}=0.203$, suggesting that if 
the focal group followed the same distribution as the reference group, the effect
size of the difference between the proportion selected the accuracy indices for
Efocal and the reference group would be 0.203. This means that the proportion
selected in the reference group is larger than the proportion selected in Efocal, indicating that *the reference group is favored when the full set of items are used*. Under the expected distribution for the reference group, the Efocal group would 
have a higher success ratio and a higher specificity than the reference group 
(full item set, and when one of items 2-4 is deleted), but would have a lower proportion selected and a lower sensitivity.
Dropping any item other than the first item would lead to a similar situation where
a greater proportion is selected from the reference group than the focal group
and is not advisable despite leading to an increase in SE.


`delta_h$h_R_vs_Ef.par`

Here, the comparison is between h values for the full item set vs. h when item i is deleted. These h values correspond to the comparison between accuracy indices for the reference group vs. the expected indices for the focal group if it followed the same distribution as the reference group, under partial invariance, i.e., looking at the change in `h$R_vs_Ef.par` when an item is deleted.

[HL]: # (I would suggest separating out PS from SR, SE, and SP here, as PS is more a fairness index whereas SR, SE, SP are more about accuracy. We may only need delta h for PS. )

[HL]: # (Should it be SE instead of PS towards the end of the first line of the equation?)

\[
\begin{align*}
\Delta h^{(-k)}(h_{\SE^{\par}_{r,Ef}}) &= \text{sign}\left(h_{\SE_{r,Ef}} - h_{\SE^{(-k)}_{r,Ef}}\right)||h_{\SE^{(-k)}_{r,Ef}}|-|h_{\PS_{r,Ef}}||\\
&=\Delta h^{(-k)}(h_{\SE^{\par}_{r,Ef})})
\end{align*}
\]

[HL]: # (I think we should modify the definition of delta h. Basically, if the -i value is closer to zero than the full item value, the sign should be positive. So let's use sign(|h-full| - |h-minu i|) instead.)

```{r }
knitr::kable(ex1$delta_h$h_R_vs_Ef.par)
```


Looking at PS, Delta h is only positive for the comparison between the full item
set and the set where item 1 is deleted. As we know that item 1 is biased, this 
indicates that seeing a positive delta h in PS is an indication that that item
should be removed. We see the opposite patterns for item 1 vs. items 2-4 where 
removing any of item 2, 3, or 4 would harm the accuracy indices.

`h$str_vs_par$ref` and `h$str_vs_par$foc` compare accuracy indices for the
reference and focal groups under strict vs. partial invariance for a given set 
of items (full, one item deleted).

\[
\begin{align*}
h^{\str,\par}(\PS^{r}) &= 2\text{arcsin}(\sqrt{\PS^{r}_{\str}})-2\text{arcsin}(\sqrt{\PS^{r}_{\par}})\\
&=h_{\PS^{r}_{\str,\par}}
\end{align*}
\]
\[
\begin{align*}
h^{\str,\par}(\PS^{(-k);r}) &= 2\text{arcsin}(\sqrt{\PS^{(-k);r}_{\str}})-2\text{arcsin}(\sqrt{\PS^{(-k);r}_{\par}})\\
&=h_{\PS^{(-k);r}_{\str,\par}}
\end{align*}
\]

```{r }
knitr::kable(ex1$h$str_vs_par$ref)
```

```{r}
knitr::kable(ex1$h$str_vs_par$foc)
```

$h_{\PS^{r}_{\str,\par}}=-0.040$ indicates that 
PS was slightly higher under partial invariance compared to under strict 
invariance for the full item set and when any of items 2-4 was deleted. Deleting
item 1 brought the effect size of the difference between strict and partial invariance conditions to 0 for all accuracy indices.

`delta_h$h_str_vs_par$ref`, `delta_h$h_str_vs_par$foc`

Here, the comparison is between h values for the full item set vs. h when item i is deleted. These h values correspond to the comparison between accuracy indices under strict vs. partial invariance, for the reference and focal groups. 

\[
\begin{align*}
\Delta h^{(-k)}(\PS^{r}_{\str,\par})&= \text{sign}\left(h_{\PS^{r}_{r}} - h_{\PS^{(-k);r}_{\str,\par}} \right)||h_{\PS^{(-k);r}_{\str,\par}} |-|h_{\PS^{r}_{\str,\par}}||\\
\end{align*}
\]
```{r }
knitr::kable(ex1$delta_h$h_str_vs_par$ref)
```





## Example from Millsap, Kwok (2004)
'Evaluating the Impact of Partial Factorial Invariance on
Selection in Two Populations'

Biased items: 3, 4
```{r}
# Worry subscale of the test anxiety inventory
ex2 <- item_deletion_h(weights_item = c(1, 1, 1, 1, 1, 1, 1, 1), 
                              propsel = 0.1000001,#"90% cutpoint"
                              #cut_z= 23.29952,
                             n_dim = 1,  
                             alpha_r = 0,
                             alpha_f =-0.126,
                             psi_r = 0.544,
                             psi_f = 0.477,
                             lambda_r_p = c(0.836, 1, 0.904, 0.808, 0.903,
                                             0.960, 0.934, 0.934),
                             lambda_f_p = c(0.836, 1, 1.111, 1.001, 0.903, 
                                             0.960, 0.934, 0.934),
                             nu_r_p = c(2.114, 2.064, 1.901, 2.004, 2.144,
                                        1.985, 2.179, 2.230),
                             nu_f_p= c(2.114, 2.064, 1.880, 1.985, 2.144,
                                        1.985, 2.179, 2.230),
                             theta_r_p = diag(c(.517, .523, .631, .585, .481,
                                                .469,.551,.572)),
                             theta_f_p = diag(c(.514, .407, .371, .475, .392,
                                                .335,.454,.457)),
                             weights_latent = 1,
                             plot_contour = FALSE,
                             return_detailed = FALSE, pmix_ref = 0.5)
```



```{r}
knitr::kable(ex2$h_overall_sai.par)
```

The positive h values in h_overall_sai_par suggest that no item should be 
dropped, as dropping any of the items would lead to a lower success ratio, lower
sensitivity, and lower specificity.

`h$R_vs_Ef.par`

```{r }
knitr::kable(ex2$h$R_vs_Ef.par)
```

If the focal group followed the same distribution as the reference group, a larger
proportion would be selected for the focal group compared to the reference group 
(indicated by the negative PS) when all items are used. If any one item is dropped
there would be an increase in PS for the reference group, leading to a positive h.

```{r }
knitr::kable(ex2$delta_h$h_R_vs_Ef.par)
```


```{r }
knitr::kable(ex2$h$str_vs_par$ref)
```

```{r}
knitr::kable(ex2$h$str_vs_par$foc)
```

A greater proportion is selected under strict invariance compared to partial 
invariance when all items are used, but when any of the 8 items are dropped, a 
greater proportion is selected under partial invariance. SR, SE, SP are always
positive, indicating that regardless of item drop condition, 
SR, SE, SP under strict invariance is always larger than SR, SE, SP under partial invariance. 


```{r }
knitr::kable(ex2$delta_h$h_str_vs_par$ref)
```


## Example from Ock, McAbee, Mulfinger, and Oswald (2020)
'The Practical Effects of Measurement Invariance: Gender Invariance in Two Big Five Personality Measures'
Biased items: 1, 7, 11, 13, 14
```{r read data, include  = FALSE}
data <- read.table("IPIPFFM.dat", header = TRUE)
head(data)
male <- data[data$sex == 1, ]
female <- data[data$sex == 2, ]
```

```{r specify and fit model}
# Multidimensional model as specified in Effect size indices.Rmd
model <- 'A =~  a2 + a5  + a7 + a9
          C =~  c3 + c4 + c8 + c9
          E =~ e1 + e4 + e6 + e7
          N =~ n1 + n2 + n6 + n8
          O =~ i2 + i8 + i9 + i10
          a2 ~~ a5
          e4 ~~ e7  
          i2 ~~ i10
          i8 ~~ i9
          a9 ~~ i9
          c3 ~~ e6
          a2 ~~ e7
          e7 ~~ n2'
fit_strict <- cfa(model, data = data, group = "sex",
                  group.equal = c("loadings", "Intercepts", "residuals"),
                  group.partial = c("e6 ~ 1", "n1 ~ 1", "n2 ~ 1", "a2 ~ 1", 
                                    #items  1 (A2), 7 (C8), 11 (E6), 13 (N1), 14 (N2)
                                    "n2 ~~ n2", "n1 ~~ n1", "c8 ~~ c8"),
                  estimator = "MLR", std.lv = TRUE)
result <- lavInspect(fit_strict, what = "est")
```

```{r IPIPFFM item deletion}
ex3 <- item_deletion_h(cut_z=2.509731,
              weights_item = c(0.008125, 0.008125, 0.008125, 0.008125,
                               0.044875, 0.044875, 0.044875, 0.044875,
                               0.117325, 0.117325, 0.117325, 0.117325,
                              -0.048775, -0.048775, -0.048775, -0.048775,
                               0.0309, 0.0309, 0.0309, 0.0309), 
              n_dim = 5, 
              alpha_r = result[[2]]$alpha,
              alpha_f = result[[1]]$alpha,
              psi_r = result[[2]]$psi,
              psi_f = result[[1]]$psi,
              lambda_r_p = result[[2]]$lambda,
              lambda_f_p = result[[1]]$lambda,
              nu_r_p = result[[2]]$nu,
              nu_f_p = result[[1]]$nu,
              theta_r_p = result[[2]]$theta,
              theta_f_p = result[[1]]$theta,
              weights_latent = c(0.0325, 0.1795, 0.4693, -0.1951, 0.1236),
              plot_contour = FALSE, 
              return_detailed = FALSE)
```

```{r}
knitr::kable(ex3$h_overall_sai.par)
```

Looking at `h_overall_sai.par`, we see that dropping item 1 would lead to
a marginal improvement in SR and SP, while SE would be unaffected. We see a similar
pattern with item 18. 

Item 12 appears to be a bad item to drop as dropping this item produces the highest
h values (i.e., the largest decrease in SR, SE, and SP) in this example, followed
by items 10 and 11. Conversely, removing item 4 would not harm SR, SP, or SE.

Out of the biased items (1, 7, 11, 13, and 14), we should consider dropping item 1
and retaining item 11.


```{r}
knitr::kable(ex3$h$R_vs_Ef.par)
```
When item 11 is dropped, h for PS is negative (a higher proportion is selected 
under Efocal than the reference group). For all other item drop conditions, h for 
PS is positive. 

```{r}
knitr::kable(ex3$h$str_vs_par$ref)
```

```{r}
knitr::kable(ex3$h$str_vs_par$foc)
```


```{r}
knitr::kable(ex3$delta_h$h_str_vs_par$ref)
```

```{r}
knitr::kable(ex3$delta_h$h_str_vs_par$foc)
```

